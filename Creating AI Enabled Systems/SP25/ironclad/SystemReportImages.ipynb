{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26e7d659-89d3-40eb-984f-3fe949ea1e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy: BruteForce\n",
      "  Query Time: 0.0000 sec\n",
      "  Retrieved Metadata: ['Person_367', 'Person_617', 'Person_846', 'Person_974', 'Person_681']\n",
      "-------------------------------------------------\n",
      "Strategy: LSH\n",
      "  Query Time: 0.0000 sec\n",
      "  Retrieved Metadata: ['Person_157', 'Person_50', 'Person_743', 'Person_264', 'Person_126']\n",
      "-------------------------------------------------\n",
      "Strategy: HNSW\n",
      "  Query Time: 0.0010 sec\n",
      "  Retrieved Metadata: ['Person_617', 'Person_846', 'Person_974', 'Person_797', 'Person_282']\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Code Cell 1: Evaluate Indexing Strategies Metrics\n",
    "# This cell loads (or simulates) a probe image, extracts its embedding, and then adds a random gallery of embeddings to each index.\n",
    "# It times the search query and prints out the retrieved metadata for each indexing strategy (BruteForce, LSH, HNSW).\n",
    "import os\n",
    "# OMP workaround\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"True\" \n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from modules.extraction.preprocessing import Preprocessing\n",
    "from modules.extraction.embedding import Embedding\n",
    "from modules.retrieval.index.bruteforce import FaissBruteForce\n",
    "from modules.retrieval.index.lsh import FaissLSH\n",
    "from modules.retrieval.index.hnsw import FaissHNSW\n",
    "\n",
    "# Placeholder for probe image path – replace with an actual image file.\n",
    "probe_image_path = \"C:\\\\Users\\\\Putna\\\\OneDrive - Johns Hopkins\\\\Documents\\\\Johns Hopkins\\\\Creating AI Enabled Systems\\\\SP25\\\\ironclad\\\\storage\\\\probe\\\\Aaron_Sorkin\\\\Aaron_Sorkin_0002.jpg\"  # Replace with your actual image path.\n",
    "embedding_dim = 512  # Adjust this if your embedding model outputs a different dimension.\n",
    "\n",
    "# Initialize preprocessing and embedding extraction modules.\n",
    "preprocessing = Preprocessing(image_size=160)\n",
    "embedding_extractor = Embedding(pretrained=\"casia-webface\", device=\"cpu\")\n",
    "\n",
    "# Load and process the probe image; if fails, use a random embedding.\n",
    "try:\n",
    "    probe_image = Image.open(probe_image_path)\n",
    "    processed_probe = preprocessing.process(probe_image)\n",
    "    query_embedding = embedding_extractor.encode(processed_probe)\n",
    "except Exception as e:\n",
    "    print(\"Error loading probe image, using a random query embedding. Details:\", e)\n",
    "    query_embedding = np.random.rand(embedding_dim).astype('float32')\n",
    "\n",
    "# Simulate a gallery of embeddings and associated metadata.\n",
    "num_gallery = 1000\n",
    "gallery_embeddings = np.random.rand(num_gallery, embedding_dim).astype('float32')\n",
    "gallery_metadata = [f\"Person_{i}\" for i in range(num_gallery)]\n",
    "k = 5  # Number of nearest neighbors to retrieve.\n",
    "\n",
    "# Initialize different indexing strategies.\n",
    "strategies = {\n",
    "    \"BruteForce\": FaissBruteForce(dim=embedding_dim, metric=\"euclidean\"),\n",
    "    \"LSH\": FaissLSH(dim=embedding_dim, nbits=128),\n",
    "    \"HNSW\": FaissHNSW(dim=embedding_dim, M=32, efConstruction=40)\n",
    "}\n",
    "\n",
    "# Dictionary to store query results.\n",
    "query_results = {}\n",
    "\n",
    "for name, index_obj in strategies.items():\n",
    "    # Add gallery embeddings to the index.\n",
    "    index_obj.add_embeddings(gallery_embeddings, gallery_metadata)\n",
    "    \n",
    "    # Time the search query.\n",
    "    start_time = time.time()\n",
    "    query_vector = query_embedding.reshape(1, -1)\n",
    "    distances, indices = index_obj.index.search(query_vector, k)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    # Retrieve metadata for the found indices.\n",
    "    meta_results = [index_obj.get_metadata(int(idx)) for idx in indices[0]]\n",
    "    \n",
    "    query_results[name] = {\n",
    "        \"query_time_sec\": elapsed_time,\n",
    "        \"distances\": distances,\n",
    "        \"indices\": indices,\n",
    "        \"metadata\": meta_results\n",
    "    }\n",
    "\n",
    "# Print the results for each indexing strategy.\n",
    "for strategy, results in query_results.items():\n",
    "    print(f\"Strategy: {strategy}\")\n",
    "    print(f\"  Query Time: {results['query_time_sec']:.4f} sec\")\n",
    "    print(f\"  Retrieved Metadata: {results['metadata']}\")\n",
    "    print(\"-------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "517af11f-1748-4bd9-83a5-c8ebc713ec3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (512,)\n",
      "Time taken for embedding extraction: 0.0205 seconds\n"
     ]
    }
   ],
   "source": [
    "# Code Cell 2: Evaluate Embedding Extraction Performance\n",
    "# This cell measures how long it takes to extract an embedding from a probe image.\n",
    "# Replace the placeholder image path with an actual image file to generate real metrics.\n",
    "\n",
    "import time\n",
    "from PIL import Image\n",
    "from modules.extraction.preprocessing import Preprocessing\n",
    "from modules.extraction.embedding import Embedding\n",
    "\n",
    "# Placeholder for probe image path – replace with an actual image file.\n",
    "probe_image_path = \"C:\\\\Users\\\\Putna\\\\OneDrive - Johns Hopkins\\\\Documents\\\\Johns Hopkins\\\\Creating AI Enabled Systems\\\\SP25\\\\ironclad\\\\storage\\\\probe\\\\Aaron_Sorkin\\\\Aaron_Sorkin_0002.jpg\"\n",
    "# Initialize preprocessing and embedding modules.\n",
    "preprocessing = Preprocessing(image_size=160)\n",
    "embedding_extractor = Embedding(pretrained=\"casia-webface\", device=\"cpu\")\n",
    "\n",
    "# Load and process the probe image.\n",
    "try:\n",
    "    probe_image = Image.open(probe_image_path)\n",
    "    processed_probe = preprocessing.process(probe_image)\n",
    "except Exception as e:\n",
    "    print(\"Error loading probe image. Using a random tensor as input. Details:\", e)\n",
    "    import torch\n",
    "    processed_probe = torch.rand(1, 3, 160, 160)\n",
    "\n",
    "# Measure the time for embedding extraction.\n",
    "start_time = time.time()\n",
    "embedding_vector = embedding_extractor.encode(processed_probe)\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"Embedding shape: {embedding_vector.shape}\")\n",
    "print(f\"Time taken for embedding extraction: {elapsed_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40e0a48a-1810-43df-b54b-25af23876bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Metric: euclidean\n",
      "  Query Time: 0.0005 sec\n",
      "  Retrieved Metadata: ['Person_151', 'Person_838', 'Person_368', 'Person_275', 'Person_569']\n",
      "-------------------------------------------------\n",
      "Similarity Metric: cosine\n",
      "  Query Time: 0.0000 sec\n",
      "  Retrieved Metadata: ['Person_838', 'Person_368', 'Person_151', 'Person_275', 'Person_743']\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Code Cell 3: Evaluate Impact of Similarity Metrics on Search Results\n",
    "# This cell compares search performance using different similarity metrics (Euclidean and Cosine)\n",
    "# on a simulated gallery using the FaissBruteForce index. It prints out query times and retrieved metadata.\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from modules.retrieval.index.bruteforce import FaissBruteForce\n",
    "\n",
    "# Define embedding dimension and simulate a gallery.\n",
    "embedding_dim = 512\n",
    "num_gallery = 1000\n",
    "gallery_embeddings = np.random.rand(num_gallery, embedding_dim).astype('float32')\n",
    "gallery_metadata = [f\"Person_{i}\" for i in range(num_gallery)]\n",
    "k = 5  # Number of nearest neighbors to retrieve.\n",
    "\n",
    "# Generate a random query embedding (or use a real one if available).\n",
    "query_embedding = np.random.rand(embedding_dim).astype('float32')\n",
    "query_vector = query_embedding.reshape(1, -1)\n",
    "\n",
    "# Evaluate for Euclidean and Cosine similarity metrics.\n",
    "metrics = [\"euclidean\", \"cosine\"]\n",
    "metric_results = {}\n",
    "\n",
    "for metric in metrics:\n",
    "    # Initialize the brute-force index with the selected metric.\n",
    "    index_obj = FaissBruteForce(dim=embedding_dim, metric=metric)\n",
    "    index_obj.add_embeddings(gallery_embeddings, gallery_metadata)\n",
    "    \n",
    "    # If using cosine, normalize the query vector so that inner product corresponds to cosine similarity.\n",
    "    if metric == \"cosine\":\n",
    "        import faiss\n",
    "        faiss.normalize_L2(query_vector)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    distances, indices = index_obj.index.search(query_vector, k)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    meta_results = [index_obj.get_metadata(int(idx)) for idx in indices[0]]\n",
    "    metric_results[metric] = {\n",
    "        \"query_time_sec\": elapsed_time,\n",
    "        \"distances\": distances,\n",
    "        \"indices\": indices,\n",
    "        \"metadata\": meta_results\n",
    "    }\n",
    "\n",
    "# Print the search results for each similarity metric.\n",
    "for metric, results in metric_results.items():\n",
    "    print(f\"Similarity Metric: {metric}\")\n",
    "    print(f\"  Query Time: {results['query_time_sec']:.4f} sec\")\n",
    "    print(f\"  Retrieved Metadata: {results['metadata']}\")\n",
    "    print(\"-------------------------------------------------\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss",
   "language": "python",
   "name": "faiss"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
