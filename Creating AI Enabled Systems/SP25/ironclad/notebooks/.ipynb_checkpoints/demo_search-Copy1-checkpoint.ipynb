{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3aefb57-d3c0-4c92-b839-9a9788e8bc15",
   "metadata": {},
   "source": [
    "### Andrew Taylor\n",
    "### atayl136\n",
    "### Creating AI Enabled Systems\n",
    "\n",
    "# Search Demo Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466541eb-dc3d-4222-973c-2bf506bc1ef2",
   "metadata": {},
   "source": [
    "# Demo Search Notebook\n",
    "This notebook demonstrates nearest neighbor search using the implemented FAISS index and various distance measures: **Euclidean**, **Cosine**, **Dot Product**, and **Minkowski**. We compute embeddings for gallery images, perform searches with 10 probe images, and report the rank positions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7abe400b-e81c-46a3-b09c-a1d4bbe893a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import sys\n",
    "# Import FAISS (will be correctly handled in the index classes)\n",
    "import faiss\n",
    "\n",
    "\n",
    "\n",
    "# Add the parent directory to the path\n",
    "# Replace '/path/to/parent/directory' with the actual path to your parent directory\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from modules.extraction.embedding import Embedding\n",
    "from modules.extraction.preprocessing import Preprocessing\n",
    "\n",
    "\n",
    "# Then import\n",
    "from modules.retrieval.index.bruteforce import FaissBruteForce\n",
    "from modules.retrieval.search import FaissSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6526c087-87b0-449c-ab2a-166fbc9c241e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"True\" \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9caeed1-7239-4415-bd74-d5f301630eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:47: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:47: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\Putna\\AppData\\Local\\Temp\\ipykernel_5496\\3473531759.py:47: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  gallery_dir = '..\\storage\\multi_image_gallery'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 folders in gallery.\n",
      "Successfully processed 10 folders\n",
      "Successfully processed 20 folders\n",
      "Successfully processed 30 folders\n",
      "Successfully processed 40 folders\n",
      "Successfully processed 50 folders\n",
      "Successfully processed 60 folders\n",
      "Successfully processed 70 folders\n",
      "Successfully processed 80 folders\n",
      "Successfully processed 90 folders\n",
      "Successfully processed 100 folders\n",
      "Successfully processed 110 folders\n",
      "Successfully processed 120 folders\n",
      "Successfully processed 130 folders\n",
      "Successfully processed 140 folders\n",
      "Successfully processed 150 folders\n",
      "Successfully processed 160 folders\n",
      "Successfully processed 170 folders\n",
      "Successfully processed 180 folders\n",
      "Successfully processed 190 folders\n",
      "Successfully processed 200 folders\n",
      "Successfully processed 210 folders\n",
      "Successfully processed 220 folders\n",
      "Successfully processed 230 folders\n",
      "Successfully processed 240 folders\n",
      "Successfully processed 250 folders\n",
      "Successfully processed 260 folders\n",
      "Successfully processed 270 folders\n",
      "Successfully processed 280 folders\n",
      "Successfully processed 290 folders\n",
      "Successfully processed 300 folders\n",
      "Successfully processed 310 folders\n",
      "Successfully processed 320 folders\n",
      "Successfully processed 330 folders\n",
      "Successfully processed 340 folders\n",
      "Successfully processed 350 folders\n",
      "Successfully processed 360 folders\n",
      "Successfully processed 370 folders\n",
      "Successfully processed 380 folders\n",
      "Successfully processed 390 folders\n",
      "Successfully processed 400 folders\n",
      "Successfully processed 410 folders\n",
      "Successfully processed 420 folders\n",
      "Successfully processed 430 folders\n",
      "Successfully processed 440 folders\n",
      "Successfully processed 450 folders\n",
      "Successfully processed 460 folders\n",
      "Successfully processed 470 folders\n",
      "Successfully processed 480 folders\n",
      "Successfully processed 490 folders\n",
      "Successfully processed 500 folders\n",
      "Successfully processed 510 folders\n",
      "Successfully processed 520 folders\n",
      "Successfully processed 530 folders\n",
      "Successfully processed 540 folders\n",
      "Successfully processed 550 folders\n",
      "Successfully processed 560 folders\n",
      "Successfully processed 570 folders\n",
      "Successfully processed 580 folders\n",
      "Successfully processed 590 folders\n",
      "Successfully processed 600 folders\n",
      "Successfully processed 610 folders\n",
      "Successfully processed 620 folders\n",
      "Successfully processed 630 folders\n",
      "Successfully processed 640 folders\n",
      "Successfully processed 650 folders\n",
      "Successfully processed 660 folders\n",
      "Successfully processed 670 folders\n",
      "Successfully processed 680 folders\n",
      "Successfully processed 690 folders\n",
      "Successfully processed 700 folders\n",
      "Successfully processed 710 folders\n",
      "Successfully processed 720 folders\n",
      "Successfully processed 730 folders\n",
      "Successfully processed 740 folders\n",
      "Successfully processed 750 folders\n",
      "Successfully processed 760 folders\n",
      "Successfully processed 770 folders\n",
      "Successfully processed 780 folders\n",
      "Successfully processed 790 folders\n",
      "Successfully processed 800 folders\n",
      "Successfully processed 810 folders\n",
      "Successfully processed 820 folders\n",
      "Successfully processed 830 folders\n",
      "Successfully processed 840 folders\n",
      "Successfully processed 850 folders\n",
      "Successfully processed 860 folders\n",
      "Successfully processed 870 folders\n",
      "Successfully processed 880 folders\n",
      "Successfully processed 890 folders\n",
      "Successfully processed 900 folders\n",
      "Successfully processed 910 folders\n",
      "Successfully processed 920 folders\n",
      "Successfully processed 930 folders\n",
      "Successfully processed 940 folders\n",
      "Successfully processed 950 folders\n",
      "Successfully processed 960 folders\n",
      "Successfully processed 970 folders\n",
      "Successfully processed 980 folders\n",
      "Successfully processed 990 folders\n",
      "Successfully processed 1000 folders\n",
      "Processing complete. Success: 1000, Errors: 0\n",
      "Created embeddings for 1000 folders\n",
      "Gallery embeddings indexed.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Initialize the preprocessing pipeline and embedding model once.\n",
    "preprocessing = Preprocessing(image_size=160)\n",
    "device = 'cpu'\n",
    "embedding_model = Embedding(pretrained='casia-webface', device=device)\n",
    "\n",
    "def compute_embedding(image_path):\n",
    "    # Open and preprocess the image.\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    processed_image = preprocessing.process(image)\n",
    "    # Compute the embedding.\n",
    "    embedding_vector = embedding_model.encode(processed_image)\n",
    "    return embedding_vector\n",
    "\n",
    "def get_first_image_from_folder(folder_path):\n",
    "    \"\"\"Get the first valid image file from a folder, skipping problematic files.\"\"\"\n",
    "    valid_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.gif']\n",
    "    \n",
    "    try:\n",
    "        for filename in os.listdir(folder_path):\n",
    "            # Skip files starting with ._ (macOS metadata files)\n",
    "            if filename.startswith('._'):\n",
    "                continue\n",
    "                \n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            if os.path.isfile(file_path) and any(file_path.lower().endswith(ext) for ext in valid_extensions):\n",
    "                # Verify it's a valid image before returning\n",
    "                try:\n",
    "                    with Image.open(file_path) as img:\n",
    "                        # Just accessing a property forces PIL to validate the file\n",
    "                        img.format\n",
    "                    return file_path\n",
    "                except Exception:\n",
    "                    # Skip this file if PIL can't open it\n",
    "                    continue\n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing folder {folder_path}: {e}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "gallery_dir = '..\\storage\\multi_image_gallery'\n",
    "folder_paths = glob.glob(os.path.join(gallery_dir, '*'))\n",
    "print(f\"Found {len(folder_paths)} folders in gallery.\")\n",
    "\n",
    "embeddings = []\n",
    "metadata = []\n",
    "successful_count = 0\n",
    "error_count = 0\n",
    "\n",
    "for folder_path in folder_paths:\n",
    "    try:\n",
    "        img_path = get_first_image_from_folder(folder_path)\n",
    "        if img_path:\n",
    "            try:\n",
    "                embedding = compute_embedding(img_path)\n",
    "                embeddings.append(embedding)\n",
    "                metadata.append(os.path.basename(folder_path))\n",
    "                successful_count += 1\n",
    "                if successful_count % 10 == 0:\n",
    "                    print(f\"Successfully processed {successful_count} folders\")\n",
    "            except Exception as e:\n",
    "                error_count += 1\n",
    "                print(f\"Error processing image {img_path}: {e}\")\n",
    "        else:\n",
    "            print(f\"No valid images found in folder: {folder_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Fatal error with folder {folder_path}: {e}\")\n",
    "\n",
    "print(f\"Processing complete. Success: {successful_count}, Errors: {error_count}\")\n",
    "\n",
    "embeddings = np.array(embeddings)\n",
    "print(f\"Created embeddings for {len(embeddings)} folders\")\n",
    "\n",
    "# Build a FAISS BruteForce index with Euclidean metric for demonstration.\n",
    "faiss_index = FaissBruteForce(dim=512, metric='euclidean')\n",
    "faiss_index.add_embeddings(embeddings, metadata)\n",
    "print(\"Gallery embeddings indexed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fdd1f2f-56c7-4b28-9d96-539c9d59206a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected probe images:\n",
      "Error processing probe image: 'numpy.ndarray' object has no attribute 'cpu'\n",
      "Error processing probe image: 'numpy.ndarray' object has no attribute 'cpu'\n",
      "Error processing probe image: 'numpy.ndarray' object has no attribute 'cpu'\n",
      "Error processing probe image: 'numpy.ndarray' object has no attribute 'cpu'\n",
      "Error processing probe image: 'numpy.ndarray' object has no attribute 'cpu'\n",
      "Error processing probe image: 'numpy.ndarray' object has no attribute 'cpu'\n",
      "Error processing probe image: 'numpy.ndarray' object has no attribute 'cpu'\n",
      "Error processing probe image: 'numpy.ndarray' object has no attribute 'cpu'\n",
      "Error processing probe image: 'numpy.ndarray' object has no attribute 'cpu'\n",
      "Error processing probe image: 'numpy.ndarray' object has no attribute 'cpu'\n"
     ]
    }
   ],
   "source": [
    "# Randomly select 10 probes from the probe directory\n",
    "probe_dir = '../storage/probe'\n",
    "probe_folders = glob.glob(os.path.join(probe_dir, '*'))\n",
    "probe_folders = np.random.choice(probe_folders, size=10, replace=False)\n",
    "\n",
    "probe_embeddings = []\n",
    "probe_metadata = []\n",
    "\n",
    "print(\"Selected probe images:\")\n",
    "for i, folder_path in enumerate(probe_folders):\n",
    "    img_path = get_first_image_from_folder(folder_path)\n",
    "    if img_path:\n",
    "        try:\n",
    "            probe_embedding = compute_embedding(img_path)\n",
    "            probe_embeddings.append(probe_embedding.cpu().numpy()) #store as numpy\n",
    "            probe_metadata.append(os.path.basename(folder_path))\n",
    "            print(f\"Probe {i+1}: {os.path.basename(folder_path)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing probe image: {e}\")\n",
    "    else:\n",
    "        print(f\"No valid image in probe folder: {folder_path}\")\n",
    "\n",
    "probe_embeddings = np.array(probe_embeddings)\n",
    "\n",
    "# Remove empty probes.\n",
    "valid_probes = []\n",
    "valid_metadata = []\n",
    "for i, probe in enumerate(probe_embeddings):\n",
    "    if probe.size > 0:\n",
    "        valid_probes.append(probe)\n",
    "        valid_metadata.append(probe_metadata[i])\n",
    "\n",
    "probe_embeddings = np.array(valid_probes)\n",
    "probe_metadata = valid_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b25187f-a9be-4654-a274-d4079e73752c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#searcher = FaissSearch(faiss_index, metric=\"euclidean\")\n",
    "#distances, indices, meta_results = searcher.search(probe, k=5)\n",
    "#print(f\"  Search completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b1c3e17-a774-4671-a7ad-d0ba61d5f0ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index size: 1000\n",
      "Index dimension: 512\n",
      "\n",
      "Distance metric: euclidean\n",
      "\n",
      "Distance metric: cosine\n",
      "\n",
      "Distance metric: dot_product\n",
      "\n",
      "Distance metric: minkowski\n"
     ]
    }
   ],
   "source": [
    "# Define the distance metrics to test.\n",
    "distance_metrics = ['euclidean', 'cosine', 'dot_product', 'minkowski']\n",
    "k = 5  # Retrieve top 5 nearest neighbors for each probe.\n",
    "\n",
    "# Dictionary to store results for each metric.\n",
    "results = {metric: [] for metric in distance_metrics}\n",
    "\n",
    "# First, check your index and ensure it's properly built\n",
    "print(f\"Index size: {faiss_index.index.ntotal}\")\n",
    "print(f\"Index dimension: {faiss_index.index.d}\")\n",
    "\n",
    "for metric in distance_metrics:\n",
    "    print(f\"\\nDistance metric: {metric}\")\n",
    "    try:\n",
    "        searcher = FaissSearch(faiss_index, metric=metric, p=3)\n",
    "\n",
    "        for i, probe in enumerate(probe_embeddings):\n",
    "            try:\n",
    "                print(f\"Searching for probe {i+1}/{len(probe_embeddings)}: {probe_metadata[i]}\")\n",
    "                probe = np.ascontiguousarray(probe, dtype='float32')\n",
    "                print(f\"  Probe shape: {probe.shape}, dtype: {probe.dtype}\")\n",
    "                print(\"  Starting search...\")\n",
    "                safe_k = min(k, faiss_index.index.ntotal)\n",
    "                print(f\"  Using k={safe_k}\")\n",
    "\n",
    "                try:\n",
    "                    distances, indices, meta_results = searcher.search(probe, k=safe_k)\n",
    "                    print(f\"  Search completed successfully\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  Search failed: {str(e)}\")\n",
    "                    print(\"  Trying direct FAISS search as fallback...\")\n",
    "                    D, I = faiss_index.index.search(probe.reshape(1, -1), safe_k)\n",
    "                    print(f\"  Direct search returned shape: {D.shape}\")\n",
    "                    distances = D\n",
    "                    indices = I\n",
    "                    meta_results = [[faiss_index.metadata[idx] for idx in I[0]]]\n",
    "\n",
    "                print(f\"  First result: {meta_results[0][0]} (Distance: {distances[0][0]:.4f})\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing probe {i}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error with metric {metric}: {str(e)}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccc94a68-2d9d-4cd4-b592-79341b6fa217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbor Ranking (Euclidean):\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Compile the Euclidean results into a summary table.\n",
    "euclidean_results = results['euclidean']\n",
    "summary = []\n",
    "for res in euclidean_results:\n",
    "    row = {'Probe': res['Probe']}\n",
    "    for rank, neighbor in enumerate(res['Neighbors'], start=1):\n",
    "        row[f'Rank {rank}'] = neighbor\n",
    "    summary.append(row)\n",
    "\n",
    "df_summary = pd.DataFrame(summary)\n",
    "print(\"Nearest Neighbor Ranking (Euclidean):\")\n",
    "print(df_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0be554bc-810e-4d08-870d-127adbad39f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Visualize the top neighbor distance for one probe across different metrics.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m probe_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# Using the first probe.\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m probe_name \u001b[38;5;241m=\u001b[39m probe_metadata[probe_idx]\n\u001b[0;32m      4\u001b[0m metric_names \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m distance_values \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Visualize the top neighbor distance for one probe across different metrics.\n",
    "probe_idx = 0  # Using the first probe.\n",
    "probe_name = probe_metadata[probe_idx]\n",
    "metric_names = []\n",
    "distance_values = []\n",
    "\n",
    "for metric in distance_metrics:\n",
    "    searcher = FaissSearch(faiss_index, metric=metric, p=3)\n",
    "    distances, indices, meta_results = searcher.search(probe_embeddings[probe_idx], k=k)\n",
    "    metric_names.append(metric)\n",
    "    distance_values.append(distances[0][0])  # Top neighbor distance.\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(metric_names, distance_values)\n",
    "plt.xlabel('Distance Metric')\n",
    "plt.ylabel('Top Neighbor Distance')\n",
    "plt.title(f'Top Neighbor Distance for Probe {probe_name}')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c10edd-0632-46e0-a258-f42f84592f75",
   "metadata": {},
   "source": [
    "## Observations\n",
    "\n",
    "- **Euclidean**, **Cosine**, and **Dot Product** metrics yield different rankings, though cosine and dot product are often similar if embeddings are normalized.\n",
    "- The **Minkowski** metric (with `p=3` in this demo) provides additional flexibility in distance measurement.\n",
    "- The choice of distance measure can affect the ranking of nearest neighbors; further tuning and experiments are necessary to determine the best fit for the application.\n",
    "## Observations\n",
    "\n",
    "- **Euclidean**, **Cosine**, and **Dot Product** metrics yield different rankings, though cosine and dot product are often similar if embeddings are normalized.\n",
    "- The **Minkowski** metric (with `p=3` in this demo) provides additional flexibility in distance measurement.\n",
    "- The choice of distance measure can affect the ranking of nearest neighbors; further tuning and experiments are necessary to determine the best fit for the application.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e337ac51-7d4a-4353-aefe-97bcd6b24e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss",
   "language": "python",
   "name": "faiss"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
