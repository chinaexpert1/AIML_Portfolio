{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration of Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probe Images:\n",
      "  Drew_Barrymore: C:\\Users\\Putna\\OneDrive - Johns Hopkins\\Documents\\Johns Hopkins\\Creating AI Enabled Systems\\SP25\\ironclad\\storage\\probe\\Drew_Barrymore\\Drew_Barrymore_0002.jpg\n",
      "  Warren_Buffett: C:\\Users\\Putna\\OneDrive - Johns Hopkins\\Documents\\Johns Hopkins\\Creating AI Enabled Systems\\SP25\\ironclad\\storage\\probe\\Warren_Buffett\\Warren_Buffett_0002.jpg\n",
      "  Owen_Wilson: C:\\Users\\Putna\\OneDrive - Johns Hopkins\\Documents\\Johns Hopkins\\Creating AI Enabled Systems\\SP25\\ironclad\\storage\\probe\\Owen_Wilson\\Owen_Wilson_0002.jpg\n",
      "  Nelson_Mandela: C:\\Users\\Putna\\OneDrive - Johns Hopkins\\Documents\\Johns Hopkins\\Creating AI Enabled Systems\\SP25\\ironclad\\storage\\probe\\Nelson_Mandela\\Nelson_Mandela_0002.jpg\n",
      "  Ian_Thorpe: C:\\Users\\Putna\\OneDrive - Johns Hopkins\\Documents\\Johns Hopkins\\Creating AI Enabled Systems\\SP25\\ironclad\\storage\\probe\\Ian_Thorpe\\Ian_Thorpe_0002.jpg\n",
      "\n",
      "Gallery Images:\n",
      "  Drew_Barrymore: C:\\Users\\Putna\\OneDrive - Johns Hopkins\\Documents\\Johns Hopkins\\Creating AI Enabled Systems\\SP25\\ironclad\\storage\\multi_image_gallery\\Drew_Barrymore\\Drew_Barrymore_0001.jpg\n",
      "  Warren_Buffett: C:\\Users\\Putna\\OneDrive - Johns Hopkins\\Documents\\Johns Hopkins\\Creating AI Enabled Systems\\SP25\\ironclad\\storage\\multi_image_gallery\\Warren_Buffett\\Warren_Buffett_0001.jpg\n",
      "  Owen_Wilson: C:\\Users\\Putna\\OneDrive - Johns Hopkins\\Documents\\Johns Hopkins\\Creating AI Enabled Systems\\SP25\\ironclad\\storage\\multi_image_gallery\\Owen_Wilson\\Owen_Wilson_0001.jpg\n",
      "  Nelson_Mandela: C:\\Users\\Putna\\OneDrive - Johns Hopkins\\Documents\\Johns Hopkins\\Creating AI Enabled Systems\\SP25\\ironclad\\storage\\multi_image_gallery\\Nelson_Mandela\\Nelson_Mandela_0001.jpg\n",
      "  Ian_Thorpe: C:\\Users\\Putna\\OneDrive - Johns Hopkins\\Documents\\Johns Hopkins\\Creating AI Enabled Systems\\SP25\\ironclad\\storage\\multi_image_gallery\\Ian_Thorpe\\Ian_Thorpe_0001.jpg\n",
      "\n",
      "Precomputed embeddings for 2265 gallery images.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# Add the parent directory to the Python path so we can import from the modules folder\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "# Import custom modules for preprocessing and embedding\n",
    "from modules.extraction.preprocessing import Preprocessing\n",
    "from modules.extraction.embedding import Embedding\n",
    "\n",
    "# ----------------------------\n",
    "# Helper Functions\n",
    "# ----------------------------\n",
    "def load_first_image(directory):\n",
    "    \"\"\"\n",
    "    Load the first valid image file found in the given directory,\n",
    "    filtering out hidden/system files.\n",
    "    \"\"\"\n",
    "    files = [f for f in os.listdir(directory)\n",
    "             if f.lower().endswith(('.jpg', '.png')) and not f.startswith(\"._\")]\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No image files found in {directory}\")\n",
    "    files.sort()  # Ensure a consistent order\n",
    "    return os.path.join(directory, files[0])\n",
    "\n",
    "def euclidean_distance(vec1, vec2):\n",
    "    return np.linalg.norm(vec1 - vec2)\n",
    "\n",
    "def dot_product_distance(vec1, vec2):\n",
    "    return -np.dot(vec1, vec2)\n",
    "\n",
    "def cosine_distance(vec1, vec2):\n",
    "    cos_sim = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "    return 1 - cos_sim\n",
    "\n",
    "def minkowski_distance(vec1, vec2, p=3):\n",
    "    return np.sum(np.abs(vec1 - vec2) ** p) ** (1/p)\n",
    "\n",
    "# ----------------------------\n",
    "# Define Global Variables and Paths\n",
    "# ----------------------------\n",
    "# List of individuals (probe identities)\n",
    "individuals = ['Drew_Barrymore', 'Warren_Buffett', 'Owen_Wilson', 'Nelson_Mandela', 'Ian_Thorpe']\n",
    "\n",
    "# Get the parent directory (assumes the structure: parent_dir/storage/...)\n",
    "parent_dir = os.path.abspath(\"..\")\n",
    "\n",
    "# Build dictionaries of file paths for probe and gallery images.\n",
    "probe_images = {}\n",
    "gallery_images = {}\n",
    "for person in individuals:\n",
    "    probe_dir = os.path.join(parent_dir, \"storage\", \"probe\", person)\n",
    "    gallery_dir = os.path.join(parent_dir, \"storage\", \"multi_image_gallery\", person)\n",
    "    probe_images[person] = load_first_image(probe_dir)\n",
    "    gallery_images[person] = load_first_image(gallery_dir)\n",
    "\n",
    "print(\"Probe Images:\")\n",
    "for person, path in probe_images.items():\n",
    "    print(f\"  {person}: {path}\")\n",
    "\n",
    "print(\"\\nGallery Images:\")\n",
    "for person, path in gallery_images.items():\n",
    "    print(f\"  {person}: {path}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Initialize Preprocessing and Embedding\n",
    "# ----------------------------\n",
    "preprocessor = Preprocessing(image_size=160)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# Initialize the embedding model (using casia-webface for gallery precomputation)\n",
    "embedding_casia = Embedding(pretrained='casia-webface', device=device)\n",
    "\n",
    "# ----------------------------\n",
    "# Precompute Gallery Embeddings (Task 2)\n",
    "# ----------------------------\n",
    "gallery_embeddings = []\n",
    "gallery_base = os.path.join(parent_dir, \"storage\", \"multi_image_gallery\")\n",
    "# List all person directories in the gallery\n",
    "persons_in_gallery = [d for d in os.listdir(gallery_base) if os.path.isdir(os.path.join(gallery_base, d))]\n",
    "\n",
    "for person in persons_in_gallery:\n",
    "    person_dir = os.path.join(gallery_base, person)\n",
    "    # Get all valid image files (filter out hidden/system files)\n",
    "    image_files = [f for f in os.listdir(person_dir)\n",
    "                   if f.lower().endswith(('.jpg', '.png')) and not f.startswith(\"._\")]\n",
    "    image_files.sort()\n",
    "    for img in image_files:\n",
    "        img_path = os.path.join(person_dir, img)\n",
    "        try:\n",
    "            image = Image.open(img_path)\n",
    "            tensor = preprocessor.process(image)\n",
    "            embedding = embedding_casia.encode(tensor)\n",
    "            gallery_embeddings.append({\"person\": person, \"image_path\": img_path, \"embedding\": embedding})\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {img_path}: {e}\")\n",
    "\n",
    "print(f\"\\nPrecomputed embeddings for {len(gallery_embeddings)} gallery images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Rank Positions for Correct Gallery Matches on Transformed Probe Images ---\n",
      "\n",
      "\n",
      "Transformation: horizontal_flip\n",
      "\n",
      "Probe Image: Drew_Barrymore (Transformation: horizontal_flip)\n",
      "  euclidean distance: Correct gallery image found at rank 188\n",
      "  dot_product distance: Correct gallery image found at rank 188\n",
      "  cosine distance: Correct gallery image found at rank 188\n",
      "  minkowski distance: Correct gallery image found at rank 180\n",
      "\n",
      "Probe Image: Warren_Buffett (Transformation: horizontal_flip)\n",
      "  euclidean distance: Correct gallery image found at rank 113\n",
      "  dot_product distance: Correct gallery image found at rank 113\n",
      "  cosine distance: Correct gallery image found at rank 113\n",
      "  minkowski distance: Correct gallery image found at rank 97\n",
      "\n",
      "Probe Image: Owen_Wilson (Transformation: horizontal_flip)\n",
      "  euclidean distance: Correct gallery image found at rank 117\n",
      "  dot_product distance: Correct gallery image found at rank 117\n",
      "  cosine distance: Correct gallery image found at rank 117\n",
      "  minkowski distance: Correct gallery image found at rank 116\n",
      "\n",
      "Probe Image: Nelson_Mandela (Transformation: horizontal_flip)\n",
      "  euclidean distance: Correct gallery image found at rank 1\n",
      "  dot_product distance: Correct gallery image found at rank 1\n",
      "  cosine distance: Correct gallery image found at rank 1\n",
      "  minkowski distance: Correct gallery image found at rank 1\n",
      "\n",
      "Probe Image: Ian_Thorpe (Transformation: horizontal_flip)\n",
      "  euclidean distance: Correct gallery image found at rank 93\n",
      "  dot_product distance: Correct gallery image found at rank 93\n",
      "  cosine distance: Correct gallery image found at rank 93\n",
      "  minkowski distance: Correct gallery image found at rank 102\n",
      "------------------------------------------------------------\n",
      "\n",
      "Transformation: gaussian_blur\n",
      "\n",
      "Probe Image: Drew_Barrymore (Transformation: gaussian_blur)\n",
      "  euclidean distance: Correct gallery image found at rank 360\n",
      "  dot_product distance: Correct gallery image found at rank 360\n",
      "  cosine distance: Correct gallery image found at rank 360\n",
      "  minkowski distance: Correct gallery image found at rank 377\n",
      "\n",
      "Probe Image: Warren_Buffett (Transformation: gaussian_blur)\n",
      "  euclidean distance: Correct gallery image found at rank 393\n",
      "  dot_product distance: Correct gallery image found at rank 393\n",
      "  cosine distance: Correct gallery image found at rank 393\n",
      "  minkowski distance: Correct gallery image found at rank 395\n",
      "\n",
      "Probe Image: Owen_Wilson (Transformation: gaussian_blur)\n",
      "  euclidean distance: Correct gallery image found at rank 355\n",
      "  dot_product distance: Correct gallery image found at rank 355\n",
      "  cosine distance: Correct gallery image found at rank 355\n",
      "  minkowski distance: Correct gallery image found at rank 375\n",
      "\n",
      "Probe Image: Nelson_Mandela (Transformation: gaussian_blur)\n",
      "  euclidean distance: Correct gallery image found at rank 1\n",
      "  dot_product distance: Correct gallery image found at rank 1\n",
      "  cosine distance: Correct gallery image found at rank 1\n",
      "  minkowski distance: Correct gallery image found at rank 1\n",
      "\n",
      "Probe Image: Ian_Thorpe (Transformation: gaussian_blur)\n",
      "  euclidean distance: Correct gallery image found at rank 29\n",
      "  dot_product distance: Correct gallery image found at rank 29\n",
      "  cosine distance: Correct gallery image found at rank 29\n",
      "  minkowski distance: Correct gallery image found at rank 23\n",
      "------------------------------------------------------------\n",
      "\n",
      "Transformation: increase_brightness\n",
      "\n",
      "Probe Image: Drew_Barrymore (Transformation: increase_brightness)\n",
      "  euclidean distance: Correct gallery image found at rank 346\n",
      "  dot_product distance: Correct gallery image found at rank 346\n",
      "  cosine distance: Correct gallery image found at rank 346\n",
      "  minkowski distance: Correct gallery image found at rank 351\n",
      "\n",
      "Probe Image: Warren_Buffett (Transformation: increase_brightness)\n",
      "  euclidean distance: Correct gallery image found at rank 923\n",
      "  dot_product distance: Correct gallery image found at rank 923\n",
      "  cosine distance: Correct gallery image found at rank 923\n",
      "  minkowski distance: Correct gallery image found at rank 915\n",
      "\n",
      "Probe Image: Owen_Wilson (Transformation: increase_brightness)\n",
      "  euclidean distance: Correct gallery image found at rank 2193\n",
      "  dot_product distance: Correct gallery image found at rank 2193\n",
      "  cosine distance: Correct gallery image found at rank 2193\n",
      "  minkowski distance: Correct gallery image found at rank 2197\n",
      "\n",
      "Probe Image: Nelson_Mandela (Transformation: increase_brightness)\n",
      "  euclidean distance: Correct gallery image found at rank 1\n",
      "  dot_product distance: Correct gallery image found at rank 1\n",
      "  cosine distance: Correct gallery image found at rank 1\n",
      "  minkowski distance: Correct gallery image found at rank 1\n",
      "\n",
      "Probe Image: Ian_Thorpe (Transformation: increase_brightness)\n",
      "  euclidean distance: Correct gallery image found at rank 98\n",
      "  dot_product distance: Correct gallery image found at rank 98\n",
      "  cosine distance: Correct gallery image found at rank 98\n",
      "  minkowski distance: Correct gallery image found at rank 98\n",
      "------------------------------------------------------------\n",
      "\n",
      "Transformation: decrease_brightness\n",
      "\n",
      "Probe Image: Drew_Barrymore (Transformation: decrease_brightness)\n",
      "  euclidean distance: Correct gallery image found at rank 356\n",
      "  dot_product distance: Correct gallery image found at rank 356\n",
      "  cosine distance: Correct gallery image found at rank 356\n",
      "  minkowski distance: Correct gallery image found at rank 361\n",
      "\n",
      "Probe Image: Warren_Buffett (Transformation: decrease_brightness)\n",
      "  euclidean distance: Correct gallery image found at rank 218\n",
      "  dot_product distance: Correct gallery image found at rank 218\n",
      "  cosine distance: Correct gallery image found at rank 218\n",
      "  minkowski distance: Correct gallery image found at rank 195\n",
      "\n",
      "Probe Image: Owen_Wilson (Transformation: decrease_brightness)\n",
      "  euclidean distance: Correct gallery image found at rank 414\n",
      "  dot_product distance: Correct gallery image found at rank 414\n",
      "  cosine distance: Correct gallery image found at rank 414\n",
      "  minkowski distance: Correct gallery image found at rank 360\n",
      "\n",
      "Probe Image: Nelson_Mandela (Transformation: decrease_brightness)\n",
      "  euclidean distance: Correct gallery image found at rank 1\n",
      "  dot_product distance: Correct gallery image found at rank 1\n",
      "  cosine distance: Correct gallery image found at rank 1\n",
      "  minkowski distance: Correct gallery image found at rank 1\n",
      "\n",
      "Probe Image: Ian_Thorpe (Transformation: decrease_brightness)\n",
      "  euclidean distance: Correct gallery image found at rank 92\n",
      "  dot_product distance: Correct gallery image found at rank 92\n",
      "  cosine distance: Correct gallery image found at rank 92\n",
      "  minkowski distance: Correct gallery image found at rank 106\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Define transformation pipelines for probe images.\n",
    "# Note: We apply these transforms to the PIL image BEFORE preprocessing.\n",
    "transformations = {\n",
    "    \"horizontal_flip\": transforms.RandomHorizontalFlip(p=1.0),\n",
    "    \"gaussian_blur\": transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),\n",
    "    \"increase_brightness\": transforms.ColorJitter(brightness=2.0),\n",
    "    \"decrease_brightness\": transforms.ColorJitter(brightness=0.5)\n",
    "}\n",
    "\n",
    "print(\"\\n--- Rank Positions for Correct Gallery Matches on Transformed Probe Images ---\\n\")\n",
    "\n",
    "# Loop through each transformation and process each probe image.\n",
    "for transform_name, transform_func in transformations.items():\n",
    "    print(f\"\\nTransformation: {transform_name}\")\n",
    "    for person in individuals:\n",
    "        # Open the original probe image.\n",
    "        image = Image.open(probe_images[person])\n",
    "        # Apply the transformation.\n",
    "        transformed_image = transform_func(image)\n",
    "        \n",
    "        # Preprocess and compute the embedding for the transformed probe image.\n",
    "        tensor = preprocessor.process(transformed_image)\n",
    "        probe_embedding = embedding_casia.encode(tensor)\n",
    "        \n",
    "        # Compute distances between the transformed probe embedding and each gallery embedding.\n",
    "        distances = {\"euclidean\": [], \"dot_product\": [], \"cosine\": [], \"minkowski\": []}\n",
    "        for gallery_entry in gallery_embeddings:\n",
    "            g_embedding = gallery_entry[\"embedding\"]\n",
    "            distances[\"euclidean\"].append((euclidean_distance(probe_embedding, g_embedding), gallery_entry))\n",
    "            distances[\"dot_product\"].append((dot_product_distance(probe_embedding, g_embedding), gallery_entry))\n",
    "            distances[\"cosine\"].append((cosine_distance(probe_embedding, g_embedding), gallery_entry))\n",
    "            distances[\"minkowski\"].append((minkowski_distance(probe_embedding, g_embedding), gallery_entry))\n",
    "        \n",
    "        # Sort the distances for each metric (lower is better).\n",
    "        for metric in distances:\n",
    "            distances[metric].sort(key=lambda x: x[0])\n",
    "        \n",
    "        # Report the rank at which the correct gallery image is found.\n",
    "        print(f\"\\nProbe Image: {person} (Transformation: {transform_name})\")\n",
    "        for metric, results_list in distances.items():\n",
    "            rank_found = None\n",
    "            for rank, (dist_val, gallery_entry) in enumerate(results_list, start=1):\n",
    "                if gallery_entry[\"person\"].lower() == person.lower():\n",
    "                    rank_found = rank\n",
    "                    break\n",
    "            if rank_found is not None:\n",
    "                print(f\"  {metric} distance: Correct gallery image found at rank {rank_found}\")\n",
    "            else:\n",
    "                print(f\"  {metric} distance: No matching gallery image found in the gallery\")\n",
    "    print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some observations based on the results for Task 4:\n",
    "\n",
    "- **Transformation Invariance Varies by Operation:**  \n",
    "  - **Horizontal Flip:**  \n",
    "    - For Drew_Barrymore, Warren_Buffett, and Owen_Wilson, the correct gallery images moved significantly higher in the ranking (e.g., Drew_Barrymore improved from rank 360 in the untransformed case to around rank 188).  \n",
    "    - This suggests that the embedding model has some invariance to horizontal flips—perhaps even improving matching performance for certain identities.\n",
    "  \n",
    "  - **Gaussian Blur:**  \n",
    "    - The performance with Gaussian blur appears similar to the untransformed scenario for many identities. For instance, Drew_Barrymore remains at rank 360, and Warren_Buffett at rank 393.  \n",
    "    - This indicates that while moderate blur might not drastically distort the facial features, it does not offer the same benefit as a horizontal flip.\n",
    "\n",
    "- **Sensitivity to Brightness Adjustments:**  \n",
    "  - **Increase Brightness:**  \n",
    "    - There is a dramatic degradation in performance for some individuals. Warren_Buffett’s rank jumps to 923, and Owen_Wilson’s rank escalates to over 2,190.  \n",
    "    - Such high ranks suggest that increasing brightness severely disrupts the discriminative features captured by the embeddings, making it harder for the correct match to stand out.\n",
    "  \n",
    "  - **Decrease Brightness:**  \n",
    "    - The effects are mixed. For Warren_Buffett, performance improves (rank 218) compared to the untransformed case, while for Owen_Wilson it only improves moderately (rank 414), and for Drew_Barrymore it remains similar.  \n",
    "    - This variability indicates that the model’s robustness to reduced brightness depends on the specific facial features of each individual.\n",
    "\n",
    "- **Robustness for Certain Identities:**  \n",
    "  - Nelson_Mandela consistently achieves a rank of 1 across all transformations, suggesting that his facial features are highly distinctive and robust to various types of image alterations.\n",
    "  - Ian_Thorpe shows moderate fluctuations (ranks in the 90s–100 range) across different transformations, hinting at some sensitivity but not as severe as the brightness increase effects observed for others.\n",
    "\n",
    "- **Consistency Across Distance Metrics:**  \n",
    "  - Across all transformations, the rank positions are nearly identical when computed with Euclidean, dot product, cosine, and Minkowski distances. This consistency reinforces that the relative structure of the embedding space is preserved regardless of the metric used.\n",
    "\n",
    "Overall, these observations highlight that while some transformations (like horizontal flip) can improve retrieval performance for certain identities, others—especially extreme brightness adjustments—can severely impair matching. This suggests a need for careful calibration of preprocessing steps in real-world applications where image quality may vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (en605645)",
   "language": "python",
   "name": "en605645"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
