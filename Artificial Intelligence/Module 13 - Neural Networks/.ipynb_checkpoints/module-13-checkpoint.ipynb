{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 13 - Programming Assignment\n",
    "\n",
    "## Directions\n",
    "\n",
    "1. Change the name of this file to be your JHED id as in `jsmith299.ipynb`. Because sure you use your JHED ID (it's made out of your name and not your student id which is just letters and numbers).\n",
    "2. Make sure the notebook you submit is cleanly and fully executed. I do not grade unexecuted notebooks.\n",
    "3. Submit your notebook back in Blackboard where you downloaded this file.\n",
    "\n",
    "*Provide the output **exactly** as requested*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Problem\n",
    "\n",
    "When we last left our agent in Module 4, it was wandering around a world filled with plains, forests, swamps, hills and mountains. This presupposes a map with known terrain:\n",
    "\n",
    "```\n",
    "......\n",
    "...**.\n",
    "...***\n",
    "..^...\n",
    "..~^..\n",
    "```\n",
    "\n",
    "but what if all we know is that we have some area of interest, that we've reduced to a GPS grid:\n",
    "\n",
    "```\n",
    "??????\n",
    "??????\n",
    "??????\n",
    "??????\n",
    "??????\n",
    "```\n",
    "\n",
    "and the agent has to determine what kind of terrain is to the left, front and right of it?\n",
    "\n",
    "Assuming the agent has a very simple visual sensor that constructs a 4x4 grayscale image for each of the three directions, it might it could see something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "plain =  [0.0, 0.0, 0.0, 0.0,0.0, 0.0, 0.0, 0.0,0.0, 0.0, 0.0, 0.0,1.0, 1.0, 1.0, 1.0]\n",
    "forest = [0.0, 1.0, 0.0, 0.0,1.0, 1.0, 1.0, 0.0,1.0, 1.0, 1.0, 1.0,0.0, 1.0, 0.0, 0.0]\n",
    "hills =  [0.0, 0.0, 0.0, 0.0,0.0, 0.0, 1.0, 0.0,0.0, 1.0, 1.0, 1.0,1.0, 1.0, 1.0, 1.0]\n",
    "swamp =  [0.0, 0.0, 0.0, 0.0,0.0, 0.0, 0.0, 0.0,1.0, 0.0, 1.0, 0.0,1.0, 1.0, 1.0, 1.0]\n",
    "\n",
    "figure = plt.figure(figsize=(20,6))\n",
    "\n",
    "axes = figure.add_subplot(1, 3, 1)\n",
    "pixels = np.array([255 - p * 255 for p in plain], dtype='uint8')\n",
    "pixels = pixels.reshape((4, 4))\n",
    "axes.set_title( \"Left Camera\")\n",
    "axes.imshow(pixels, cmap='gray')\n",
    "\n",
    "axes = figure.add_subplot(1, 3, 2)\n",
    "pixels = np.array([255 - p * 255 for p in forest], dtype='uint8')\n",
    "pixels = pixels.reshape((4, 4))\n",
    "axes.set_title( \"Front Camera\")\n",
    "axes.imshow(pixels, cmap='gray')\n",
    "\n",
    "axes = figure.add_subplot(1, 3, 3)\n",
    "pixels = np.array([255 - p * 255 for p in hills], dtype='uint8')\n",
    "pixels = pixels.reshape((4, 4))\n",
    "axes.set_title( \"Right Camera\")\n",
    "axes.imshow(pixels, cmap='gray')\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which would be plains, forest and hills respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Assignment\n",
    "\n",
    "In Assignment 12, we applied a logistic regression to determine if something was \"hills\" or \"not hills\". For this programming assignment your task is to write an artificial neural network that determines what kind of terrain it is. This is a multi-class problem.\n",
    "\n",
    "For a starting point, you can refer to Pseudocode and the Self-Check."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "As before, we have clean examples of the different types of terrain but based on the location, the registration can be a bit off for some of the types and the visual sensor is often blurry.\n",
    "\n",
    "Here are the clean examples with different registrations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = {\n",
    "    \"plains\": [\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, \"plains\"]\n",
    "    ],\n",
    "    \"forest\": [\n",
    "        [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, \"forest\"],\n",
    "        [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, \"forest\"],\n",
    "        [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, \"forest\"],\n",
    "        [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, \"forest\"]\n",
    "    ],\n",
    "    \"hills\": [\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, \"hills\"],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, \"hills\"],\n",
    "        [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, \"hills\"],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, \"hills\"]\n",
    "    ],\n",
    "    \"swamp\": [\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, \"swamp\"],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, \"swamp\"]        \n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a function that allows us to view any of these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_sensor_image( data):\n",
    "    figure = plt.figure(figsize=(4,4))\n",
    "    axes = figure.add_subplot(1, 1, 1)\n",
    "    pixels = np.array([255 - p * 255 for p in data[:-1]], dtype='uint8')\n",
    "    pixels = pixels.reshape((4, 4))\n",
    "    axes.set_title( \"Left Camera:\" + data[-1])\n",
    "    axes.imshow(pixels, cmap='gray')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"I think that I shall never see a thing so lovely as a tree.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_sensor_image( clean_data[ \"forest\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_sensor_image( clean_data[\"swamp\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data that comes in, however, is noisy. The values are never exactly 0 and 1. In order to mimic this we need a `blur` function.\n",
    "\n",
    "We will assume that noise is normally distributed. For values that should be 0, the noisy values are distributed $N(0.10, 0.05)$. For values should be 1, the noisy values are distributed $N(0.9, 0.10)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur( data):\n",
    "    def apply_noise( value):\n",
    "        if value < 0.5:\n",
    "            v = random.gauss( 0.10, 0.05)\n",
    "            if v < 0.0:\n",
    "                return 0.0\n",
    "            if v > 0.75:\n",
    "                return 0.75\n",
    "            return v\n",
    "        else:\n",
    "            v = random.gauss( 0.90, 0.10)\n",
    "            if v < 0.25:\n",
    "                return 0.25\n",
    "            if v > 1.00:\n",
    "                return 1.00\n",
    "            return v\n",
    "    noisy_readings = [apply_noise( v) for v in data[0:-1]]\n",
    "    return noisy_readings + [data[-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how this affects what the agent *actually* sees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_sensor_image( blur( clean_data[\"swamp\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are going to want to write four (4) functions:\n",
    "\n",
    "1. `generate_data`\n",
    "2. `learn_model`\n",
    "3. `apply_model`\n",
    "\n",
    "### `generate_data`\n",
    "\n",
    "With the clean examples and the `blur` function, we have an unlimited amount of data for training and testing our classifier, an ANN that determines if a sensor image is hills, swamp, forest or plains.\n",
    "\n",
    "In classification, there is a general problem called the \"unbalanced class problem\". In general, we want our training data to have the same number of classes for each class. This means you should probably generate training data with, say, 100 of each type.\n",
    "\n",
    "But what do we do about the class label with the neural network?\n",
    "\n",
    "In this case, we can do \"one hot\". Instead of `generate_data` outputing a single 0 or 1, it should output a vector of 0's and 1's so that $y$ is now a vector as well as $x$. We can use the first position for hill, the second for swamp, the third for forest and the fourth for plains:\n",
    "\n",
    "```\n",
    "[0, 1, 0, 0]\n",
    "```\n",
    "\n",
    "what am I? swamp.\n",
    "\n",
    "Unlike logistic regression, you should set the *biases* inside the neural network (the implict $x_0$ = 1) because there are going to be lot of them (one for every hidden and output node).\n",
    "\n",
    "`generate_data` now only needs to take how many you want of each class:\n",
    "\n",
    "`generate_data( clean_data, 100)`\n",
    "\n",
    "generates 100 hills, 100 swamp, 100 forest, 100 plains and transforms $y$ into the respective \"one hot\" encoding. You can use the code from Module 12 as a starting point.\n",
    "\n",
    "### `learn_model`\n",
    "\n",
    "`learn_model` is the function that takes in training data and actually learns the ANN. If you're up to it, you can implement a vectorized version using Numpy but you might start with the loopy version first.\n",
    "\n",
    "*In the lecture, I mentioned that you usually should mean normalize your data but you don't need to do that in this case because the data is already on the range 0-1.*\n",
    "\n",
    "You should add a parameter to indicate how many nodes the hidden layer should have.\n",
    "\n",
    "When verbose is True, you should print out the error so you can see that it is getting smaller.\n",
    "\n",
    "When developing your algorithm, you need to watch the error so you'll set verbose=True to start. You should print it out every iteration and make sure it is declining. You'll have to experiment with both epsilon and alpha; and it doesn't hurt to make alpha adaptive (if the error increases, make alpha = alpha / 10).\n",
    "\n",
    "When you know that your algorithm is working, change your code so that the error is printed out only every 1,000 iterations (it takes a lot of iterations for this problem to converge, depending on your parameter values--start early).\n",
    "\n",
    "`learn_model` returns the neural network. The hidden layer will be one vector of thetas for each hidden node. And the output layer will have its own thetas, one for each output (4 in this case). Return it as a Tuple: (List of List, List of List).\n",
    "\n",
    "### `apply_model`\n",
    "\n",
    "`apply_model` takes the ANN (the model) and either labeled or unlabeled data. If the data is unlabeled, it will return predictions for each observation as a List of Tuples of the inferred value (0 or 1) and the actual probability (so something like (1, 0.73) or (0, 0.19) so you have [(0, 0.30), (1, 0.98), (0, 0.87), (0, 0.12)]. Note that unlike the logistic regression, the threshold for 1 is not 0.5 but which value is largest (0.98 in this case).\n",
    "\n",
    "If the data is labeled, you will return a List of List of Tuples of the actual value (0 or 1) and the predicted value (0 or 1). For a single data point, you'll have the pairs of actual values [(0, 1), (0, 0), (0, 0), (1, 0)] is a misclassification and [(0, 0), (0, 0), (1, 1), (0, 0)] will be a correct classification. Then you have a List of *those*, one for each observation.\n",
    "\n",
    "###  simple evaluation\n",
    "\n",
    "We have an \"unlimited\" supply of data so we'll just generate a training set and then a test set and see how well our neural network does. Use the error rate (incorrect classifications/total examples) for your evaluation metric. We'll learn about more sophisticated \n",
    "\n",
    "1. generate training set (how many do you think you need?)\n",
    "2. generate test set (how many is a good \"test\" of the network you built?)\n",
    "3. loop over [2, 4, 8] hidden nodes:\n",
    "    1. train model and apply to train data, calculate error rate.\n",
    "    2. apply to test data and calculate error rate.\n",
    "    3. print error rate\n",
    "    \n",
    "Which number of hidden nodes did best?\n",
    "\n",
    "**As always when working with Lists or Lists of Lists, be very careful when you are modifying these items in place that this is what you intend (you may want to make a copy first)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Put your helper functions above here.\n",
    "\n",
    "## Main Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate_data\n",
    "\n",
    "Generates an endless supply of blurred data from a collection of terrain prototypes.\n",
    "\n",
    "* `data`: Dict[Str, List[Any]] - a Dictionary of \"clean\" prototypes for each landscape type.\n",
    "* `n`: Int - the number of blurred examples of each terrain type to return.\n",
    "\n",
    "returns\n",
    "\n",
    "* List[List[Any]] - a List of Lists. Each individual List is a blurred example of a terrain type, generated from the prototype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_data(data, n):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learn_model\n",
    "\n",
    "**put documentation here based on the assignment description**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def learn_model( data, hidden_nodes, verbose=False):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply_model\n",
    "\n",
    "**put documentation here based on the assignment description**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model( model, test_data, labeled=False):\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test out generate_data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = generate_data( clean_data, 10)\n",
    "for result in results:\n",
    "    print( result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `generate_data` to generate 100 blurred examples of each type (all four terrains)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = generate_data( clean_data, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `learn_model` to learn a ANN model for classifying sensor images as hills, swamps, plains or forest. **Set Verbose to True**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = learn_model( train_data, 2, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `generate_data` to generate 100 blurred examples of each terrain and use this as your test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = generate_data( clean_data, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the model and evaluate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = apply_model( model, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print( results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you're pretty sure your algorithm works (the error rate during training is going down, and you can evaluate `apply_model` results for its error rate), you need to determine what the best number of hidden nodes is.\n",
    "\n",
    "Try 2, 4, or 8 hidden nodes and indicate the best one. Follow the outline above under \"Simple Evaluation\".\n",
    "In the \"real world\", you could 10 fold cross validation and validation curves to determine the number of hidden nodes and possibly if you needed one or two hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which number of hidden nodes is best? ____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before You Submit...\n",
    "\n",
    "1. Did you provide output exactly as requested?\n",
    "2. Did you re-execute the entire notebook? (\"Restart Kernel and Rull All Cells...\")\n",
    "3. If you did not complete the assignment or had difficulty please explain what gave you the most difficulty in the Markdown cell below.\n",
    "4. Did you change the name of the file to `jhed_id.ipynb`?\n",
    "\n",
    "Do not submit any other files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "207px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
